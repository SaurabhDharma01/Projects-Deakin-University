{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6979ba9a",
   "metadata": {},
   "source": [
    "# Q1. Load \"digits\" datasets from SKlearn. Classify digit classes using KNN. Use the same data splitting and performance metrics that you have used in previous week (week 4). Report your findings including comparison of results with week 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb33a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df56267c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       0.98      1.00      0.99        54\n",
      "           4       0.98      1.00      0.99        60\n",
      "           5       0.98      0.98      0.98        66\n",
      "           6       1.00      1.00      1.00        53\n",
      "           7       1.00      1.00      1.00        55\n",
      "           8       1.00      1.00      1.00        43\n",
      "           9       0.98      0.95      0.97        59\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the \"digits\" dataset\n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "target = digits.target\n",
    "\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Fit the KNN classifier to the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the KNN classifier on the test set\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# Print the classification report for KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee513d",
   "metadata": {},
   "source": [
    "**Comparison:**  \n",
    "\n",
    "***KNN Model:***\n",
    "\n",
    "Accuracy: 0.99\n",
    "Overall precision, recall, and F1-score are very high, indicating excellent performance.\n",
    "The KNN model achieved near-perfect classification for most digit classes.  \n",
    "\n",
    "***SVM Model:***\n",
    "\n",
    "Accuracy: 0.77\n",
    "The SVM model's performance was significantly lower compared to KNN.\n",
    "Precision, recall, and F1-score are relatively lower, especially for some digit classes.\n",
    "\n",
    "KNN Model has performed far better than SVM Model. It has performed better in all aspects in determining the right class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c2ff4",
   "metadata": {},
   "source": [
    "# Q2. Create digits classification model using DT algorithm using 50-50% and 70-30% data splitting methods. Compare performances of these two models and explain the impact of difference in data splitting on the performances of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e759d4f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 50-50% Data Splitting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        82\n",
      "           1       0.78      0.70      0.74        89\n",
      "           2       0.85      0.93      0.89        83\n",
      "           3       0.86      0.72      0.78        93\n",
      "           4       0.83      0.87      0.85        93\n",
      "           5       0.81      0.83      0.82        99\n",
      "           6       0.88      0.93      0.90        98\n",
      "           7       0.91      0.93      0.92        87\n",
      "           8       0.68      0.69      0.68        83\n",
      "           9       0.79      0.84      0.81        92\n",
      "\n",
      "    accuracy                           0.84       899\n",
      "   macro avg       0.84      0.84      0.83       899\n",
      "weighted avg       0.84      0.84      0.83       899\n",
      "\n",
      "\n",
      "Classification Report for 70-30% Data Splitting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        53\n",
      "           1       0.74      0.78      0.76        50\n",
      "           2       0.83      0.74      0.79        47\n",
      "           3       0.78      0.85      0.81        54\n",
      "           4       0.81      0.85      0.83        60\n",
      "           5       0.92      0.86      0.89        66\n",
      "           6       0.93      0.94      0.93        53\n",
      "           7       0.85      0.84      0.84        55\n",
      "           8       0.89      0.77      0.82        43\n",
      "           9       0.78      0.85      0.81        59\n",
      "\n",
      "    accuracy                           0.84       540\n",
      "   macro avg       0.85      0.84      0.84       540\n",
      "weighted avg       0.85      0.84      0.84       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Data splitting with 50-50% method\n",
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(data, target, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data splitting with 70-30% method\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(data, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create Decision Tree classifiers for both data splitting methods\n",
    "dt_classifier_50 = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier_70 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the models on the training data\n",
    "dt_classifier_50.fit(X_train_50, y_train_50)\n",
    "dt_classifier_70.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Evaluate the models on the test data\n",
    "y_pred_50 = dt_classifier_50.predict(X_test_50)\n",
    "y_pred_70 = dt_classifier_70.predict(X_test_70)\n",
    "\n",
    "# Print the classification reports for both models\n",
    "print(\"Classification Report for 50-50% Data Splitting:\")\n",
    "print(classification_report(y_test_50, y_pred_50))\n",
    "\n",
    "print(\"\\nClassification Report for 70-30% Data Splitting:\")\n",
    "print(classification_report(y_test_70, y_pred_70))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3939be",
   "metadata": {},
   "source": [
    "**Comparison:**  \n",
    "After looking at the results above. We can say,  \n",
    "50-50% data split and 70-30% data split both have achieved an accuracy of 84%. It does not have any major impact on our performance. Generally it is a good practice to provide a big training set as machine is able to learn better woth a bogger dataset. In this case both the models have performed and generalised well. So our Decision Tree model has learnt and has been able to perform very well on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bfcd01",
   "metadata": {},
   "source": [
    "# Q3. Create two more KNN-based classification models using the dataset used in Q1 by varying distance metrics such as using cityblock and cosine. Report the performances of the developed models including Q1 and explain the similarity or differences if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df3c946",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report (Euclidean Distance):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       0.98      1.00      0.99        54\n",
      "           4       0.98      1.00      0.99        60\n",
      "           5       0.98      0.98      0.98        66\n",
      "           6       1.00      1.00      1.00        53\n",
      "           7       1.00      1.00      1.00        55\n",
      "           8       1.00      1.00      1.00        43\n",
      "           9       0.98      0.95      0.97        59\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n",
      "\n",
      "KNN Classification Report (Cityblock Distance):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       0.96      1.00      0.98        50\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       0.98      1.00      0.99        54\n",
      "           4       0.98      1.00      0.99        60\n",
      "           5       0.98      0.98      0.98        66\n",
      "           6       1.00      0.98      0.99        53\n",
      "           7       1.00      0.98      0.99        55\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       0.95      0.95      0.95        59\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n",
      "\n",
      "KNN Classification Report (Cosine Distance):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.96      1.00      0.98        50\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       0.98      1.00      0.99        54\n",
      "           4       0.98      1.00      0.99        60\n",
      "           5       0.99      1.00      0.99        66\n",
      "           6       1.00      1.00      1.00        53\n",
      "           7       1.00      1.00      1.00        55\n",
      "           8       1.00      0.95      0.98        43\n",
      "           9       1.00      0.95      0.97        59\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data splitting with 70-30% method\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create KNN classifiers with different distance metrics\n",
    "knn_euclidean = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn_cityblock = KNeighborsClassifier(n_neighbors=5, metric='cityblock')\n",
    "knn_cosine = KNeighborsClassifier(n_neighbors=5, metric='cosine')\n",
    "\n",
    "# Train the models on the training data\n",
    "knn_euclidean.fit(X_train, y_train)\n",
    "knn_cityblock.fit(X_train, y_train)\n",
    "knn_cosine.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the models on the test data\n",
    "y_pred_euclidean = knn_euclidean.predict(X_test)\n",
    "y_pred_cityblock = knn_cityblock.predict(X_test)\n",
    "y_pred_cosine = knn_cosine.predict(X_test)\n",
    "\n",
    "# Print the classification reports for all three models\n",
    "print(\"KNN Classification Report (Euclidean Distance):\")\n",
    "print(classification_report(y_test, y_pred_euclidean))\n",
    "\n",
    "print(\"\\nKNN Classification Report (Cityblock Distance):\")\n",
    "print(classification_report(y_test, y_pred_cityblock))\n",
    "\n",
    "print(\"\\nKNN Classification Report (Cosine Distance):\")\n",
    "print(classification_report(y_test, y_pred_cosine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7541a",
   "metadata": {},
   "source": [
    "**Comparison:**  \n",
    "\n",
    "***Similarities:***  \n",
    "All three are performing very well. Cosine and Euclidian model give a score of 99% and Cityblock model give an accuracy of 98%.  \n",
    "Again Cosine and Euclidian model give precision, recall and F1 score of 1.  \n",
    "\n",
    "***Differences:***  \n",
    "Cityblock model gives 1% lower accuracy than other two models at 98%.  \n",
    "Aslo there are minor differences in precision and recall in cityblock model but overall the model is performing very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d91936",
   "metadata": {},
   "source": [
    "# Q4. Creating random forest model using HR-Employee-Attrition.csv dataset and improve the result using hyperparameter tuning. Hints. Visualise your performance fluctuation for different hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3634071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HR-Employee-Attrition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c301b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2487f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Age                       1470 non-null   int64 \n",
      " 1   Attrition                 1470 non-null   object\n",
      " 2   BusinessTravel            1470 non-null   object\n",
      " 3   DailyRate                 1470 non-null   int64 \n",
      " 4   Department                1470 non-null   object\n",
      " 5   DistanceFromHome          1470 non-null   int64 \n",
      " 6   Education                 1470 non-null   int64 \n",
      " 7   EducationField            1470 non-null   object\n",
      " 8   EmployeeCount             1470 non-null   int64 \n",
      " 9   EmployeeNumber            1470 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1470 non-null   int64 \n",
      " 11  Gender                    1470 non-null   object\n",
      " 12  HourlyRate                1470 non-null   int64 \n",
      " 13  JobInvolvement            1470 non-null   int64 \n",
      " 14  JobLevel                  1470 non-null   int64 \n",
      " 15  JobRole                   1470 non-null   object\n",
      " 16  JobSatisfaction           1470 non-null   int64 \n",
      " 17  MaritalStatus             1470 non-null   object\n",
      " 18  MonthlyIncome             1470 non-null   int64 \n",
      " 19  MonthlyRate               1470 non-null   int64 \n",
      " 20  NumCompaniesWorked        1470 non-null   int64 \n",
      " 21  Over18                    1470 non-null   object\n",
      " 22  OverTime                  1470 non-null   object\n",
      " 23  PercentSalaryHike         1470 non-null   int64 \n",
      " 24  PerformanceRating         1470 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1470 non-null   int64 \n",
      " 26  StandardHours             1470 non-null   int64 \n",
      " 27  StockOptionLevel          1470 non-null   int64 \n",
      " 28  TotalWorkingYears         1470 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1470 non-null   int64 \n",
      " 30  WorkLifeBalance           1470 non-null   int64 \n",
      " 31  YearsAtCompany            1470 non-null   int64 \n",
      " 32  YearsInCurrentRole        1470 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1470 non-null   int64 \n",
      " 34  YearsWithCurrManager      1470 non-null   int64 \n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 402.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb3c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Random Forest Classifier:\n",
      "Accuracy: 0.8741496598639455\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.99      0.93       255\n",
      "         Yes       0.67      0.10      0.18        39\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.77      0.55      0.55       294\n",
      "weighted avg       0.85      0.87      0.83       294\n",
      "\n",
      "Confusion Matrix:\n",
      "[[253   2]\n",
      " [ 35   4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocess the data\n",
    "# Assuming the target variable is 'Attrition' and removing irrelevant columns if any\n",
    "X = df.drop(['Attrition', 'EmployeeNumber'], axis=1)\n",
    "y = df['Attrition']\n",
    "\n",
    "# Encoding categorical variables using one-hot encoding\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier with default hyperparameters\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Print the classification report and accuracy for the default model\n",
    "print(\"Default Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652cb110",
   "metadata": {},
   "source": [
    "### Hyper Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65ae4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arun\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Model Accuracy: 0.8809523809523809\n",
      "\n",
      "Classification Report for Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      1.00      0.94       255\n",
      "         Yes       1.00      0.10      0.19        39\n",
      "\n",
      "    accuracy                           0.88       294\n",
      "   macro avg       0.94      0.55      0.56       294\n",
      "weighted avg       0.90      0.88      0.84       294\n",
      "\n",
      "Confusion Matrix for Best Model:\n",
      "[[255   0]\n",
      " [ 35   4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Create the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search using cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_best = best_rf_model.predict(X_test)\n",
    "\n",
    "# Print the best hyperparameters and performance metrics for the best model\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "print(\"Best Model Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"\\nClassification Report for Best Model:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"Confusion Matrix for Best Model:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a61e57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b9b9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the results of the grid search\n",
    "results = grid_search.cv_results_\n",
    "params = results['params']\n",
    "mean_test_scores = results['mean_test_score']\n",
    "\n",
    "# Extract the hyperparameter values from the grid search results\n",
    "n_estimators = [param['n_estimators'] for param in params]\n",
    "max_depth = [param['max_depth'] for param in params]\n",
    "min_samples_split = [param['min_samples_split'] for param in params]\n",
    "min_samples_leaf = [param['min_samples_leaf'] for param in params]\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "data = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'mean_test_score': mean_test_scores\n",
    "}\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "# Pivot the dataframe to create a heatmap\n",
    "pivot_table = df_results.pivot_table(values='mean_test_score',\n",
    "                                     index='min_samples_split',\n",
    "                                     columns='min_samples_leaf',\n",
    "                                     aggfunc='mean')\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_table, annot=True, cmap='YlGnBu', fmt=\".3f\", linewidths=0.5)\n",
    "plt.title(\"Hyperparameter Tuning - Mean Test Score\")\n",
    "plt.xlabel(\"Min Samples Leaf\")\n",
    "plt.ylabel(\"Min Samples Split\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd70b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a110eda0",
   "metadata": {},
   "source": [
    "\n",
    "The table shows the mean test scores (accuracy) for different combinations of min_samples_split and min_samples_leaf hyperparameters during the hyperparameter tuning process for the Random Forest classifier.  \n",
    "\n",
    "The values of min_samples_split are 2, 5, and 10.  \n",
    "\n",
    "The values of min_samples_leaf are 1, 2, and 4.\n",
    "\n",
    "The numbers in the cells of the table represent the mean test scores (accuracy) for each combination of min_samples_split and min_samples_leaf. The accuracy values are given with three decimal places.\n",
    "\n",
    "Highest performance is generated with a min_sample_split = 2 and min_sample_leaf = 1, with accuracy = 85.3%.  \n",
    "\n",
    "Other prameters are still at par with the highest performing one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edaa12",
   "metadata": {},
   "source": [
    "# Q5. Creating GradientBoost model using HR-Employee-Attrition.csv dataset and improve the result using hyperparameter tuning. Hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0980733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea4baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Gradient Boosting Classifier:\n",
      "Accuracy: 0.8673469387755102\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.89      0.97      0.93       255\n",
      "         Yes       0.50      0.18      0.26        39\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.69      0.58      0.60       294\n",
      "weighted avg       0.83      0.87      0.84       294\n",
      "\n",
      "Confusion Matrix:\n",
      "[[248   7]\n",
      " [ 32   7]]\n",
      "\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best Model Accuracy: 0.8877551020408163\n",
      "\n",
      "Classification Report for Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.90      0.98      0.94       255\n",
      "         Yes       0.69      0.28      0.40        39\n",
      "\n",
      "    accuracy                           0.89       294\n",
      "   macro avg       0.79      0.63      0.67       294\n",
      "weighted avg       0.87      0.89      0.87       294\n",
      "\n",
      "Confusion Matrix for Best Model:\n",
      "[[250   5]\n",
      " [ 28  11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"HR-Employee-Attrition.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop(['Attrition', 'EmployeeNumber'], axis=1)\n",
    "y = df['Attrition']\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Print the default model's performance\n",
    "print(\"Default Gradient Boosting Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Create the Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search using cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(gb_classifier, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_best = best_gb_model.predict(X_test)\n",
    "\n",
    "# Print the best hyperparameters and performance metrics for the best model\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "print(\"Best Model Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"\\nClassification Report for Best Model:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"Confusion Matrix for Best Model:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f93c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46371e8c",
   "metadata": {},
   "source": [
    "# Q6. Compare the best model after hyperparameter tuning found in Q4 and Q5, and explain which model is good and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515e784",
   "metadata": {},
   "source": [
    "**Random Forest Classifier Model**\n",
    "\n",
    "Hyperparameters: max_depth=None, max_features='auto', min_samples_leaf=2, min_samples_split=5, n_estimators=100  \n",
    "Accuracy: 88.10%  \n",
    "Recall for 'Yes' class: 10%  \n",
    "F1-score for 'Yes' class: 0.19  \n",
    "\n",
    "\n",
    "**Gradient Boosting Classifier Model**  \n",
    "\n",
    "Hyperparameters: learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8  \n",
    "Accuracy: 88.78%  \n",
    "Recall for 'Yes' class: 28%  \n",
    "F1-score for 'Yes' class: 0.40  \n",
    "\n",
    "Based on the comparison, Gradient Boosting model is the better model. It has a slightly higher accuracy and notably better performance in terms of recall, F1-score, and other metrics. However, it's important to note that both models might still benefit from further tuning, especially in terms of addressing the class imbalance and exploring more sophisticated techniques to enhance the recognition of the 'Yes' class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac6213",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd0bd6be",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "GeeksforGeeks. (2023, January 10). \"Decision Tree Implementation in Python.\" GeeksforGeeks. https://www.geeksforgeeks.org/decision-tree-implementation-python/ [Accessed August 20, 2023].\n",
    "\n",
    "Pattabiraman Gurumoorthy. (2022). \"Data Mining.\" Course Code: PGP-DSBA. Great Lakes. Olympus.\n",
    "\n",
    "Patel Dhaval. (2018, Nov 17). \"Machine Learning Tutorial Python - 9 Decision Tree.\" YouTube. https://www.youtube.com/watch?v=PHxYNGo8NcI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356ca7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
